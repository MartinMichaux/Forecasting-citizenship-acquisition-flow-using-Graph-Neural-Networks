{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('data/features/features_interpolated.csv', encoding='latin-1', engine='python')\n",
    "df_features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "immigration = pd.read_csv('data/labels/OECD_acquisition_data_interpolated.csv', encoding='latin-1', engine='python')\n",
    "immigration.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country  Year  Carbon Emissions  Education Expenditure  \\\n",
      "0     AUS  2000          339446.6               4.887310   \n",
      "1     AUS  2001          345645.0               4.889552   \n",
      "2     AUS  2002          353371.3               4.891794   \n",
      "3     AUS  2003          352581.1               4.894036   \n",
      "4     AUS  2004          365808.0               4.896278   \n",
      "\n",
      "   Foreign Direct Investment (FDI) Inflows           GDP  Health Expenditure  \\\n",
      "0                             1.489298e+10  4.158513e+11            7.599617   \n",
      "1                             1.071713e+10  3.793582e+11            7.682723   \n",
      "2                             1.465632e+10  3.955808e+11            7.878076   \n",
      "3                             8.985246e+09  4.674980e+11            7.882926   \n",
      "4                             4.290767e+10  6.143264e+11            8.090034   \n",
      "\n",
      "   Inflation Rate  Internet Penetration  Life Expectancy  \\\n",
      "0        4.457435             46.756116        79.234146   \n",
      "1        4.407135             52.689266        79.634146   \n",
      "2        2.981575             55.266950        79.936585   \n",
      "3        2.732596             57.844633        80.239024   \n",
      "4        2.343255             60.422317        80.490244   \n",
      "\n",
      "   Renewable Energy Production  Unemployment Rate  \n",
      "0                         8.42               6.28  \n",
      "1                         8.37               6.74  \n",
      "2                         8.74               6.37  \n",
      "3                         7.15               5.93  \n",
      "4                         6.68               5.39  \n",
      "   CO2  COU  Year  Value\n",
      "0  GBR  BEL  2000  152.0\n",
      "1  GBR  BEL  2001  274.0\n",
      "2  GBR  BEL  2002  201.0\n",
      "3  GBR  BEL  2003  126.0\n",
      "4  GBR  BEL  2004  128.0\n"
     ]
    }
   ],
   "source": [
    "print(df_features.head())\n",
    "print(immigration.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each year, create a graph based on the similarities of the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Carbon Emissions', 'Education Expenditure',\n",
      "       'Foreign Direct Investment (FDI) Inflows', 'GDP', 'Health Expenditure',\n",
      "       'Inflation Rate', 'Internet Penetration', 'Life Expectancy',\n",
      "       'Renewable Energy Production', 'Unemployment Rate'],\n",
      "      dtype='object')\n",
      "[2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n",
      " 2014 2015 2016 2017 2018 2019 2020]\n",
      "['GBR' 'BEL' 'GRC' 'CHE' 'SVN' 'ITA' 'MEX' 'DEU' 'CHL' 'USA' 'FRA' 'POL'\n",
      " 'LUX' 'HUN' 'NOR' 'FIN' 'IRL' 'SWE' 'ESP' 'DNK' 'CAN' 'ISL' 'AUT' 'AUS'\n",
      " 'NLD' 'LVA' 'NZL']\n"
     ]
    }
   ],
   "source": [
    "# get all features names except country and year\n",
    "features = df_features.columns[2:]\n",
    "years = immigration['Year'].unique()\n",
    "countries = immigration['CO2'].unique()\n",
    "\n",
    "print(features)\n",
    "print(years)\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a threshold for each feature similarity score to be considered\n",
    "threshold_ce = 0.5\n",
    "threshold_ee = 0.5\n",
    "threshold_fdi = 0.5\n",
    "threshold_gpd = 0.5\n",
    "threshold_he = 0.5\n",
    "threshold_ir = 0.5\n",
    "threshold_ip = 0.5\n",
    "threshold_le = 0.5\n",
    "threshold_rep = 0.5\n",
    "threshold_ur = 0.5\n",
    "\n",
    "# Set the minimum number of threshold crossings required\n",
    "min_threshold_crossings = 5\n",
    "\n",
    "similarity_thresholds = [threshold_ce, threshold_ee, threshold_fdi, threshold_gpd, threshold_he,\n",
    "                         threshold_ir, threshold_ip, threshold_le, threshold_rep, threshold_ur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(df,k=2):\n",
    "    # similarity_ce = cosine_similarity(df['Carbon Emissions'].values.reshape(-1, 1), df['Carbon Emissions'].values.reshape(-1, 1))\n",
    "    # similarity_ee = cosine_similarity(df['Education Expenditure'].values.reshape(-1, 1), df['Education Expenditure'].values.reshape(-1, 1))\n",
    "    # similarity_fdi = cosine_similarity(df['Foreign Direct Investment (FDI) Inflows'].values.reshape(-1, 1), df['Foreign Direct Investment (FDI) Inflows'].values.reshape(-1, 1))\n",
    "    # similarity_gpd = cosine_similarity(df['GDP'].values.reshape(-1, 1), df['GDP'].values.reshape(-1, 1))\n",
    "    # similarity_he = cosine_similarity(df['Health Expenditure'].values.reshape(-1, 1), df['Health Expenditure'].values.reshape(-1, 1))\n",
    "    # similarity_ir = cosine_similarity(df['Inflation Rate'].values.reshape(-1, 1), df['Inflation Rate'].values.reshape(-1, 1))\n",
    "    # similarity_ip = cosine_similarity(df['Internet Penetration'].values.reshape(-1, 1), df['Internet Penetration'].values.reshape(-1, 1))\n",
    "    # similarity_le = cosine_similarity(df['Life Expectancy'].values.reshape(-1, 1), df['Life Expectancy'].values.reshape(-1, 1))\n",
    "    # similarity_rep = cosine_similarity(df['Renewable Energy Production'].values.reshape(-1, 1), df['Renewable Energy Production'].values.reshape(-1, 1))\n",
    "    # similarity_ur = cosine_similarity(df['Unemployment Rate'].values.reshape(-1, 1), df['Unemployment Rate'].values.reshape(-1, 1))\n",
    "    \n",
    "    # similarity_ce = cdist(df['Carbon Emissions'].values.reshape(-1, 1), df['Carbon Emissions'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_ee = cdist(df['Education Expenditure'].values.reshape(-1, 1), df['Education Expenditure'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_fdi = cdist(df['Foreign Direct Investment (FDI) Inflows'].values.reshape(-1, 1), df['Foreign Direct Investment (FDI) Inflows'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_gpd = cdist(df['GDP'].values.reshape(-1, 1), df['GDP'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_he = cdist(df['Health Expenditure'].values.reshape(-1, 1), df['Health Expenditure'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_ir = cdist(df['Inflation Rate'].values.reshape(-1, 1), df['Inflation Rate'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_ip = cdist(df['Internet Penetration'].values.reshape(-1, 1), df['Internet Penetration'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_le = cdist(df['Life Expectancy'].values.reshape(-1, 1), df['Life Expectancy'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_rep = cdist(df['Renewable Energy Production'].values.reshape(-1, 1), df['Renewable Energy Production'].values.reshape(-1, 1), metric='canberra')\n",
    "    # similarity_ur = cdist(df['Unemployment Rate'].values.reshape(-1, 1), df['Unemployment Rate'].values.reshape(-1, 1), metric='canberra')\n",
    "    \n",
    "    # return similarity_ce, similarity_ee, similarity_fdi, similarity_gpd, similarity_he, \\\n",
    "    #         similarity_ir, similarity_ip, similarity_le, similarity_rep, similarity_ur\n",
    "    \n",
    "    # Create a NearestNeighbors object\n",
    "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "\n",
    "    # Fit the data to the NearestNeighbors model\n",
    "    neighbors.fit(df.values)\n",
    "\n",
    "    # Compute the distances and indices of the k-nearest neighbors\n",
    "    distances, indices = neighbors.kneighbors(df.values)\n",
    "\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(df), len(df)))\n",
    "\n",
    "    # Fill the similarity matrix with k-NN similarities\n",
    "    for i in range(len(df)):\n",
    "        for j in indices[i]:\n",
    "            if i != j:\n",
    "                similarity_matrix[i, j] = 1.0\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Graph Sparsity: 0.43304843304843305\n",
      "2001\n",
      "Graph Sparsity: 0.5071225071225072\n",
      "2002\n",
      "Graph Sparsity: 0.5356125356125356\n",
      "2003\n",
      "Graph Sparsity: 0.43304843304843305\n",
      "2004\n",
      "Graph Sparsity: 0.4444444444444444\n",
      "2005\n",
      "Graph Sparsity: 0.4415954415954416\n",
      "2006\n",
      "Graph Sparsity: 0.45014245014245013\n",
      "2007\n",
      "Graph Sparsity: 0.43874643874643876\n",
      "2008\n",
      "Graph Sparsity: 0.48717948717948717\n",
      "2009\n",
      "Graph Sparsity: 0.452991452991453\n",
      "2010\n",
      "Graph Sparsity: 0.4586894586894587\n",
      "2011\n",
      "Graph Sparsity: 0.4700854700854701\n",
      "2012\n",
      "Graph Sparsity: 0.43304843304843305\n",
      "2013\n",
      "Graph Sparsity: 0.43874643874643876\n",
      "2014\n",
      "Graph Sparsity: 0.4586894586894587\n",
      "2015\n",
      "Graph Sparsity: 0.4415954415954416\n",
      "2016\n",
      "Graph Sparsity: 0.4472934472934473\n",
      "2017\n",
      "Graph Sparsity: 0.4358974358974359\n",
      "2018\n",
      "Graph Sparsity: 0.43304843304843305\n",
      "2019\n",
      "Graph Sparsity: 0.43874643874643876\n",
      "2020\n",
      "Graph Sparsity: 0.452991452991453\n"
     ]
    }
   ],
   "source": [
    "graphs=[]\n",
    "k = 15\n",
    "\n",
    "# for each year create the graph\n",
    "for year in years:\n",
    "    print(year)\n",
    "    # empty graph\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    df = df_features[df_features['Year'] == year]\n",
    "    \n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the features before computing similarity\n",
    "    normalized_features = scaler.fit_transform(df[['Carbon Emissions', 'Education Expenditure', 'Foreign Direct Investment (FDI) Inflows',\n",
    "                                                'GDP', 'Health Expenditure', 'Inflation Rate', 'Internet Penetration',\n",
    "                                                'Life Expectancy', 'Renewable Energy Production', 'Unemployment Rate']])\n",
    "\n",
    "    # Create a new DataFrame with the normalized features\n",
    "    df_normalized = pd.DataFrame(normalized_features, columns=['Carbon Emissions', 'Education Expenditure', 'Foreign Direct Investment (FDI) Inflows',\n",
    "                                                            'GDP', 'Health Expenditure', 'Inflation Rate', 'Internet Penetration',\n",
    "                                                            'Life Expectancy', 'Renewable Energy Production', 'Unemployment Rate'])\n",
    "\n",
    "    # Compute similarity using the normalized features\n",
    "    # similarity_ce, similarity_ee, similarity_fdi, similarity_gpd, similarity_he, \\\n",
    "    #         similarity_ir, similarity_ip, similarity_le, similarity_rep, similarity_ur = compute_similarities(df_normalized)\n",
    "    similarity_matrix = compute_similarities(df_normalized,k)\n",
    "            \n",
    "    # Add countries as nodes to the graph and add all their features as node attributes\n",
    "    for i, row in df.iterrows():\n",
    "        graph.add_node(row['Country'], x=[row['Carbon Emissions'],\n",
    "                                          row['Education Expenditure'],\n",
    "                                          row['Foreign Direct Investment (FDI) Inflows'],\n",
    "                                          row['GDP'],\n",
    "                                          row['Health Expenditure'],\n",
    "                                          row['Inflation Rate'],\n",
    "                                          row['Internet Penetration'],\n",
    "                                          row['Life Expectancy'],\n",
    "                                          row['Renewable Energy Production'],\n",
    "                                          row['Unemployment Rate']])\n",
    "\n",
    "        \n",
    "    # Add edges based on similarity scores and threshold crossings\n",
    "    num_countries = len(countries)\n",
    "    for i in range(num_countries):\n",
    "        for j in range(i + 1, num_countries):\n",
    "            country1 = countries[i]\n",
    "            country2 = countries[j]\n",
    "            # Check if the nodes already exist in the graph\n",
    "            if country1 in graph.nodes() and country2 in graph.nodes():\n",
    "                # similarity_score = [similarity_ce[i][j], similarity_ee[i][j], similarity_fdi[i][j], similarity_gpd[i][j], similarity_he[i][j],\n",
    "                #                      similarity_ir[i][j], similarity_ip[i][j], similarity_le[i][j], similarity_rep[i][j], similarity_ur[i][j]]\n",
    "\n",
    "                # Count the number of threshold crossings\n",
    "                # threshold_crossings = sum(score > threshold for score, threshold in zip(similarity_scores, similarity_thresholds))\n",
    "\n",
    "                # if threshold_crossings >= min_threshold_crossings:\n",
    "                \n",
    "                similarity_score = similarity_matrix[i, j]\n",
    "            \n",
    "                if similarity_score > 0:\n",
    "                    edge_value = immigration[(immigration['CO2'] == country1) & (immigration['COU'] == country2) & (immigration['Year'] == year)]['Value'].values[0]\n",
    "            \n",
    "                    # graph.add_edge(country1, country2, weight=sum(similarity_score), edge_value=edge_value)  # Add edge with maximum similarity score as weight and edge value\n",
    "                    graph.add_edge(country1, country2, weight=similarity_score, edge_value=edge_value)  # Add edge with maximum similarity score as weight and edge value\n",
    "\n",
    "    \n",
    "    # Calculate the number of edges and nodes in the graph\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "\n",
    "    # Calculate the maximum number of edges possible in an undirected graph\n",
    "    max_edges = (num_nodes * (num_nodes - 1)) / 2\n",
    "\n",
    "    # Calculate the sparsity of the graph\n",
    "    sparsity = num_edges / max_edges\n",
    "\n",
    "    # Print the sparsity\n",
    "    print(\"Graph Sparsity:\", sparsity)\n",
    "    \n",
    "    graphs.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "    Carbon Emissions  Education Expenditure  \\\n0           0.079918               0.649351   \n1           0.013108               0.426407   \n2           0.018972               0.781385   \n3           0.120134               0.448052   \n4           0.007421               0.458874   \n5           0.018632               0.545048   \n6           0.136161               0.337662   \n7           0.005826               0.709957   \n8           0.049489               0.322511   \n9           0.008113               0.601732   \n10          0.062059               0.519481   \n11          0.072110               0.525974   \n12          0.012118               0.290043   \n13          0.009291               0.359307   \n14          0.007083               0.000000   \n15          0.000000               1.000000   \n16          0.065531               0.253247   \n17          0.001631               0.404762   \n18          0.001232               0.621212   \n19          0.092945               0.249831   \n20          0.030046               0.476191   \n21          0.007124               0.606061   \n22          0.006722               0.623377   \n23          0.060941               0.452381   \n24          0.002484               0.575758   \n25          0.006928               0.880952   \n26          1.000000               0.638528   \n\n    Foreign Direct Investment (FDI) Inflows       GDP  Health Expenditure  \\\n0                                  0.282224  0.065569            0.393326   \n1                                  0.261103  0.019527            0.506579   \n2                                  0.280949  0.024410            0.424194   \n3                                  0.349908  0.084276            0.469827   \n4                                  0.255995  0.033278            0.478558   \n5                                  0.266060  0.012514            0.277982   \n6                                  0.365037  0.181813            0.553515   \n7                                  0.265139  0.016003            0.407985   \n8                                  0.314628  0.060189            0.398136   \n9                                  0.280665  0.011666            0.316404   \n10                                 0.390074  0.125906            0.508918   \n11                                 0.250250  0.133355            0.489161   \n12                                 0.250606  0.008127            0.308583   \n13                                 0.289945  0.006709            0.140855   \n14                                 0.377518  0.020549            0.102057   \n15                                 0.240397  0.000000            0.319336   \n16                                 0.272263  0.089401            0.304578   \n17                                 0.224869  0.002572            0.000000   \n18                                 0.246519  0.000612            0.155438   \n19                                 0.296732  0.053554            0.065963   \n20                                 0.000000  0.042390            0.435099   \n21                                 0.264243  0.019604            0.351525   \n22                                 0.247907  0.009630            0.347239   \n23                                 0.303110  0.028075            0.092037   \n24                                 0.243854  0.001552            0.282343   \n25                                 0.329495  0.026195            0.440195   \n26                                 1.000000  1.000000            1.000000   \n\n    Inflation Rate  Internet Penetration  Life Expectancy  \\\n0         0.446822              0.861146         0.959583   \n1         0.427782              0.711663         0.808465   \n2         0.363871              0.722171         0.856215   \n3         0.550844              0.723944         0.908008   \n4         0.000000              0.834156         1.000000   \n5         0.771970              0.617572         0.640186   \n6         0.486521              0.667411         0.783678   \n7         0.248900              0.966921         0.820626   \n8         0.491703              0.766885         0.950641   \n9         0.315770              0.722899         0.859434   \n10        0.207644              0.452499         0.888048   \n11        0.379167              0.878879         0.768942   \n12        0.125702              0.146303         0.731028   \n13        0.886783              0.555032         0.311833   \n14        0.347796              0.818026         0.871774   \n15        0.756242              1.000000         0.946170   \n16        0.252961              0.000000         0.922563   \n17        0.380841              0.958629         0.919165   \n18        0.527474              0.657302         0.225097   \n19        1.000000              0.030783         0.000000   \n20        0.409975              0.692482         0.824739   \n21        0.568209              0.972325         0.949568   \n22        0.657734              0.847860         0.879464   \n23        0.875831              0.423473         0.395172   \n24        0.261435              0.569661         0.781818   \n25        0.309626              0.541616         0.949031   \n26        0.805899              0.680406         0.448465   \n\n    Renewable Energy Production  Unemployment Rate  \n0                      0.021922           0.154116  \n1                      0.347856           0.246935  \n2                      0.023025           0.253940  \n3                      0.187095           0.359019  \n4                      0.223632           0.152364  \n5                      0.230525           0.524518  \n6                      0.118985           0.018389  \n7                      0.399559           0.148862  \n8                      0.120364           1.000000  \n9                      0.513167           0.372154  \n10                     0.096374           0.394046  \n11                     0.051013           0.128371  \n12                     0.137460           0.993870  \n13                     0.070316           0.060420  \n14                     0.052392           0.247811  \n15                     1.000000           0.232925  \n16                     0.120364           0.537653  \n17                     0.109058           0.165499  \n18                     0.454708           0.363398  \n19                     0.024817           0.063923  \n20                     0.000000           0.074431  \n21                     0.742176           0.088441  \n22                     0.291052           0.036778  \n23                     0.050186           0.000000  \n24                     0.169861           0.120841  \n25                     0.611333           0.469352  \n26                     0.025920           0.174256  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Carbon Emissions</th>\n      <th>Education Expenditure</th>\n      <th>Foreign Direct Investment (FDI) Inflows</th>\n      <th>GDP</th>\n      <th>Health Expenditure</th>\n      <th>Inflation Rate</th>\n      <th>Internet Penetration</th>\n      <th>Life Expectancy</th>\n      <th>Renewable Energy Production</th>\n      <th>Unemployment Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.079918</td>\n      <td>0.649351</td>\n      <td>0.282224</td>\n      <td>0.065569</td>\n      <td>0.393326</td>\n      <td>0.446822</td>\n      <td>0.861146</td>\n      <td>0.959583</td>\n      <td>0.021922</td>\n      <td>0.154116</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.013108</td>\n      <td>0.426407</td>\n      <td>0.261103</td>\n      <td>0.019527</td>\n      <td>0.506579</td>\n      <td>0.427782</td>\n      <td>0.711663</td>\n      <td>0.808465</td>\n      <td>0.347856</td>\n      <td>0.246935</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.018972</td>\n      <td>0.781385</td>\n      <td>0.280949</td>\n      <td>0.024410</td>\n      <td>0.424194</td>\n      <td>0.363871</td>\n      <td>0.722171</td>\n      <td>0.856215</td>\n      <td>0.023025</td>\n      <td>0.253940</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.120134</td>\n      <td>0.448052</td>\n      <td>0.349908</td>\n      <td>0.084276</td>\n      <td>0.469827</td>\n      <td>0.550844</td>\n      <td>0.723944</td>\n      <td>0.908008</td>\n      <td>0.187095</td>\n      <td>0.359019</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.007421</td>\n      <td>0.458874</td>\n      <td>0.255995</td>\n      <td>0.033278</td>\n      <td>0.478558</td>\n      <td>0.000000</td>\n      <td>0.834156</td>\n      <td>1.000000</td>\n      <td>0.223632</td>\n      <td>0.152364</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.018632</td>\n      <td>0.545048</td>\n      <td>0.266060</td>\n      <td>0.012514</td>\n      <td>0.277982</td>\n      <td>0.771970</td>\n      <td>0.617572</td>\n      <td>0.640186</td>\n      <td>0.230525</td>\n      <td>0.524518</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.136161</td>\n      <td>0.337662</td>\n      <td>0.365037</td>\n      <td>0.181813</td>\n      <td>0.553515</td>\n      <td>0.486521</td>\n      <td>0.667411</td>\n      <td>0.783678</td>\n      <td>0.118985</td>\n      <td>0.018389</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.005826</td>\n      <td>0.709957</td>\n      <td>0.265139</td>\n      <td>0.016003</td>\n      <td>0.407985</td>\n      <td>0.248900</td>\n      <td>0.966921</td>\n      <td>0.820626</td>\n      <td>0.399559</td>\n      <td>0.148862</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.049489</td>\n      <td>0.322511</td>\n      <td>0.314628</td>\n      <td>0.060189</td>\n      <td>0.398136</td>\n      <td>0.491703</td>\n      <td>0.766885</td>\n      <td>0.950641</td>\n      <td>0.120364</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.008113</td>\n      <td>0.601732</td>\n      <td>0.280665</td>\n      <td>0.011666</td>\n      <td>0.316404</td>\n      <td>0.315770</td>\n      <td>0.722899</td>\n      <td>0.859434</td>\n      <td>0.513167</td>\n      <td>0.372154</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.062059</td>\n      <td>0.519481</td>\n      <td>0.390074</td>\n      <td>0.125906</td>\n      <td>0.508918</td>\n      <td>0.207644</td>\n      <td>0.452499</td>\n      <td>0.888048</td>\n      <td>0.096374</td>\n      <td>0.394046</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.072110</td>\n      <td>0.525974</td>\n      <td>0.250250</td>\n      <td>0.133355</td>\n      <td>0.489161</td>\n      <td>0.379167</td>\n      <td>0.878879</td>\n      <td>0.768942</td>\n      <td>0.051013</td>\n      <td>0.128371</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.012118</td>\n      <td>0.290043</td>\n      <td>0.250606</td>\n      <td>0.008127</td>\n      <td>0.308583</td>\n      <td>0.125702</td>\n      <td>0.146303</td>\n      <td>0.731028</td>\n      <td>0.137460</td>\n      <td>0.993870</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.009291</td>\n      <td>0.359307</td>\n      <td>0.289945</td>\n      <td>0.006709</td>\n      <td>0.140855</td>\n      <td>0.886783</td>\n      <td>0.555032</td>\n      <td>0.311833</td>\n      <td>0.070316</td>\n      <td>0.060420</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.007083</td>\n      <td>0.000000</td>\n      <td>0.377518</td>\n      <td>0.020549</td>\n      <td>0.102057</td>\n      <td>0.347796</td>\n      <td>0.818026</td>\n      <td>0.871774</td>\n      <td>0.052392</td>\n      <td>0.247811</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.240397</td>\n      <td>0.000000</td>\n      <td>0.319336</td>\n      <td>0.756242</td>\n      <td>1.000000</td>\n      <td>0.946170</td>\n      <td>1.000000</td>\n      <td>0.232925</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.065531</td>\n      <td>0.253247</td>\n      <td>0.272263</td>\n      <td>0.089401</td>\n      <td>0.304578</td>\n      <td>0.252961</td>\n      <td>0.000000</td>\n      <td>0.922563</td>\n      <td>0.120364</td>\n      <td>0.537653</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.001631</td>\n      <td>0.404762</td>\n      <td>0.224869</td>\n      <td>0.002572</td>\n      <td>0.000000</td>\n      <td>0.380841</td>\n      <td>0.958629</td>\n      <td>0.919165</td>\n      <td>0.109058</td>\n      <td>0.165499</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.001232</td>\n      <td>0.621212</td>\n      <td>0.246519</td>\n      <td>0.000612</td>\n      <td>0.155438</td>\n      <td>0.527474</td>\n      <td>0.657302</td>\n      <td>0.225097</td>\n      <td>0.454708</td>\n      <td>0.363398</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.092945</td>\n      <td>0.249831</td>\n      <td>0.296732</td>\n      <td>0.053554</td>\n      <td>0.065963</td>\n      <td>1.000000</td>\n      <td>0.030783</td>\n      <td>0.000000</td>\n      <td>0.024817</td>\n      <td>0.063923</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.030046</td>\n      <td>0.476191</td>\n      <td>0.000000</td>\n      <td>0.042390</td>\n      <td>0.435099</td>\n      <td>0.409975</td>\n      <td>0.692482</td>\n      <td>0.824739</td>\n      <td>0.000000</td>\n      <td>0.074431</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.007124</td>\n      <td>0.606061</td>\n      <td>0.264243</td>\n      <td>0.019604</td>\n      <td>0.351525</td>\n      <td>0.568209</td>\n      <td>0.972325</td>\n      <td>0.949568</td>\n      <td>0.742176</td>\n      <td>0.088441</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.006722</td>\n      <td>0.623377</td>\n      <td>0.247907</td>\n      <td>0.009630</td>\n      <td>0.347239</td>\n      <td>0.657734</td>\n      <td>0.847860</td>\n      <td>0.879464</td>\n      <td>0.291052</td>\n      <td>0.036778</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.060941</td>\n      <td>0.452381</td>\n      <td>0.303110</td>\n      <td>0.028075</td>\n      <td>0.092037</td>\n      <td>0.875831</td>\n      <td>0.423473</td>\n      <td>0.395172</td>\n      <td>0.050186</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.002484</td>\n      <td>0.575758</td>\n      <td>0.243854</td>\n      <td>0.001552</td>\n      <td>0.282343</td>\n      <td>0.261435</td>\n      <td>0.569661</td>\n      <td>0.781818</td>\n      <td>0.169861</td>\n      <td>0.120841</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.006928</td>\n      <td>0.880952</td>\n      <td>0.329495</td>\n      <td>0.026195</td>\n      <td>0.440195</td>\n      <td>0.309626</td>\n      <td>0.541616</td>\n      <td>0.949031</td>\n      <td>0.611333</td>\n      <td>0.469352</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1.000000</td>\n      <td>0.638528</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.805899</td>\n      <td>0.680406</td>\n      <td>0.448465</td>\n      <td>0.025920</td>\n      <td>0.174256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]\n",
    "df_normalized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n          2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n          5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n          6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n          8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n         13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n         14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16,\n         16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n         17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n         19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20,\n         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21,\n         21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n         22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n         23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n         24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26,\n         26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26],\n        [ 5, 12, 13, 15, 18,  8, 10, 11, 12, 13, 17, 18, 19, 23, 11, 13, 15, 17,\n         18, 19, 23, 24,  5, 12, 13, 17, 18, 19, 23, 24,  5,  6, 11, 12, 13, 14,\n         15, 17, 18, 23, 24, 26,  0,  3,  4,  6, 10, 11, 13, 15, 18, 19, 20, 23,\n         25, 26,  4,  5,  7,  9, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24,\n         25,  6,  8, 11, 13, 15, 17, 18, 19, 23, 24,  1,  7, 13, 15, 17, 18, 21,\n         22, 25, 26,  6, 11, 13, 17, 18, 19, 20, 23, 24, 26,  1,  5, 13, 14, 15,\n         17, 18, 19, 21, 22, 23, 25, 26,  1,  2,  4,  5,  7,  9, 12, 13, 14, 15,\n         17, 18, 19, 20, 21, 22, 23, 24, 25, 26,  0,  1,  3,  4,  6, 11, 14, 15,\n         16, 17, 18, 19, 20, 21, 22, 23, 25, 26,  0,  1,  2,  3,  4,  5,  6,  7,\n          8,  9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26,  4,  6, 10,\n         11, 12, 15, 17, 18, 19, 20, 26,  0,  2,  4,  5,  6,  7,  8, 10, 11, 12,\n         13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 26, 12, 13, 15, 18, 21, 22, 24,\n         25, 26,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 18, 19,\n         20, 21, 22, 23, 25, 26,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n         12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26,  1,  2,  3,  5,\n          6,  7,  9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26,  5,\n          6,  9, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24,  6,  8, 10, 11, 12,\n         13, 16, 17, 18, 19, 23, 24,  6,  8, 10, 11, 12, 13, 16, 17, 18, 19, 20,\n         23,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 15, 17, 18, 20, 21, 22,\n         24, 25, 26,  2,  3,  4,  6,  7,  9, 11, 13, 15, 16, 18, 19, 20, 21, 23,\n         25, 26,  5,  6,  8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 23, 24, 26,  4,\n          5,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24, 25]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graph = from_networkx(graphs[0])\n",
    "pyg_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "migration_graphs = []\n",
    "for year in immigration[\"Year\"].unique():\n",
    "    migration_g = nx.from_pandas_edgelist(df=immigration[immigration[\"Year\"] == year], source=\"CO2\", target=\"COU\", edge_attr=\"Value\")\n",
    "    migration_graphs.append(migration_g)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "NodeDataView({'GBR': {}, 'BEL': {}, 'GRC': {}, 'CHE': {}, 'SVN': {}, 'ITA': {}, 'MEX': {}, 'DEU': {}, 'CHL': {}, 'USA': {}, 'FRA': {}, 'POL': {}, 'LUX': {}, 'HUN': {}, 'NOR': {}, 'FIN': {}, 'IRL': {}, 'SWE': {}, 'ESP': {}, 'DNK': {}, 'CAN': {}, 'ISL': {}, 'AUT': {}, 'AUS': {}, 'NLD': {}, 'LVA': {}, 'NZL': {}})"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migration_graphs[0].nodes(data=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "pyg_graphs = [from_networkx(g) for g in migration_graphs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 702], Value=[702], num_nodes=27)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graphs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pyg_graphs[:15]\n",
    "test_data = pyg_graphs[15:]\n",
    "len(test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): GNNEncoder(\n",
      "    (conv1): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "    (conv2): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "  )\n",
      "  (decoder): EdgeDecoder(\n",
      "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "    loss = F.mse_loss(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, 301):\n",
    "    train_data = train_data.to(device)\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
